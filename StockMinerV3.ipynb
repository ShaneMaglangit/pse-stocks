{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StockMinerV3.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1eOoXjwdHFqLrlO9wruhOkvo2lctGAJt0","authorship_tag":"ABX9TyO6V7HXx2rbP7BfXTOqELDk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"o5QjKxOW5xy3"},"source":["# Install and import libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZA73Fmj5Z5Z","collapsed":true,"executionInfo":{"status":"ok","timestamp":1616592314009,"user_tz":-480,"elapsed":44923,"user":{"displayName":"Shane Francis Maglangit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gif9jiIJsudPe_sgYE9xBV4g1Qy2JgQntoZsU9Q=s64","userId":"00349401743727072180"}},"outputId":"91f615ac-d749-4d6c-bd05-bb82fee69596"},"source":["!pip install lxml\n","!pip install selenium\n","!pip install cssselect\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n","Collecting selenium\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n","\u001b[K     |████████████████████████████████| 911kB 10.5MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n","Installing collected packages: selenium\n","Successfully installed selenium-3.141.0\n","Collecting cssselect\n","  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n","Installing collected packages: cssselect\n","Successfully installed cssselect-1.1.0\n","Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,748 kB]\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [894 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,460 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [373 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,168 kB]\n","Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [49.4 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,400 kB]\n","Get:23 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [344 kB]\n","Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,031 kB]\n","Fetched 11.8 MB in 3s (3,906 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 57 not upgraded.\n","Need to get 83.2 MB of archives.\n","After this operation, 282 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 89.0.4389.82-0ubuntu0.18.04.1 [1,127 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 89.0.4389.82-0ubuntu0.18.04.1 [73.6 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 89.0.4389.82-0ubuntu0.18.04.1 [3,800 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 89.0.4389.82-0ubuntu0.18.04.1 [4,697 kB]\n","Fetched 83.2 MB in 2s (52.9 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 160980 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_89.0.4389.82-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (89.0.4389.82-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (89.0.4389.82-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRTFdE9K528k","executionInfo":{"status":"ok","timestamp":1616592315742,"user_tz":-480,"elapsed":46648,"user":{"displayName":"Shane Francis Maglangit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gif9jiIJsudPe_sgYE9xBV4g1Qy2JgQntoZsU9Q=s64","userId":"00349401743727072180"}},"outputId":"3c550a06-b7a1-47a7-9d78-8b629a99012e"},"source":["import pandas as pd\n","import numpy as np\n","\n","from lxml import html\n","from lxml.cssselect import CSSSelector\n","\n","# Create the web driver\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.common.exceptions import TimeoutException\n","\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n","from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","driver = webdriver.Chrome('chromedriver',options=chrome_options)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: use options instead of chrome_options\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wpSRecHg7XVd"},"source":["# Load the site"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nkIh_Bg7Y51","executionInfo":{"status":"ok","timestamp":1616592330234,"user_tz":-480,"elapsed":61133,"user":{"displayName":"Shane Francis Maglangit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gif9jiIJsudPe_sgYE9xBV4g1Qy2JgQntoZsU9Q=s64","userId":"00349401743727072180"}},"outputId":"23cbf87c-9ec8-4592-9078-365d881a12c5"},"source":["url = \"https://ph.investing.com/equities/philippines\"\n","driver.get(url)\n","driver.implicitly_wait(10)\n","\n","# Show all stocks\n","filter = driver.find_element_by_css_selector(\"#stocksFilter\")\n","filter.find_element_by_css_selector(\"option#all\").click()\n","\n","# Create a list where we will store our links\n","stock_links = []\n","\n","try:\n","  # This is the css selector for the anchor tag that contains our desired url\n","  links_selector = \"#cross_rate_markets_stocks_1 tbody tr td:nth-child(2) a\"\n","  # We will use WebDriverWait() to ensure that the element has actually loaded before we try and retrieve it\n","  anchors = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, links_selector)))\n","\n","  # Once we get the list of anchor elements, we will iterate through each of them and store\n","  # the stock name and url to our stock_links list\n","  for anchor in anchors:\n","    anchor_href = anchor.get_attribute(\"href\").split(\"?\")\n","    stock_links.append({\n","        \"name\": anchor.get_attribute(\"title\"),\n","        \"url\": anchor_href[0] + \"-historical-data\" + \"?\" + \"?\".join(anchor_href[1:])\n","    })\n","\n","  # Show a confirmation that the process is successful and how many stocks did we collected\n","  print(\"Retrieved\", len(stock_links), \"URLs\")\n","except TimeoutException:\n","  print(\"Element not properly loaded\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Retrieved 303 URLs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XksHArthB17c"},"source":["def get_historical_data(stocks):\n","  # List where we will store our collected data\n","  historical_data = []\n","  # A variable to keep track of our progress\n","  count = 0\n","\n","  # We'll iterate through all of our collected URLs\n","  for stock in stocks:\n","    count += 1\n","    try:\n","      # List where we will temporarily store the historical data for a specific stock code\n","      stock_data = []\n","\n","      # Load the url on our web driver\n","      driver.get(stock[\"url\"])\n","      driver.implicitly_wait(10)\n","\n","      # We would have to modify the filters such that we can get the oldest\n","      # data as possible\n","\n","      # This line selects the widget for the date and excecute a javascript code\n","      # to perform the click event for us\n","      date_widget = driver.find_element_by_id(\"widgetField\")\n","      driver.execute_script(\"arguments[0].click();\", date_widget)\n","\n","      # We would now set the start date field to 08/08/1927, date where the PSE\n","      # was originally founded\n","      start_date = driver.find_element_by_id(\"startDate\")\n","      start_date.clear()\n","      start_date.send_keys(\"08/08/1927\")\n","\n","      # Finally, we would apply our changes to update our displayed data\n","      apply_widget = driver.find_element_by_id(\"applyBtn\")\n","      driver.execute_script(\"arguments[0].click();\", apply_widget)\n","\n","      # Now we would get the only h2 element in the page which contains the stock code\n","      stock_code = driver.find_element_by_tag_name(\"h2\").get_attribute(\"innerHTML\")\n","      stock_code = stock_code.split(\" \")[0]\n","\n","      # We would now extract the table body's HTML source from the page\n","      # Note: The table body contains the all the stock price data that we need\n","      table_body = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#curr_table tbody\")))\n","\n","      # We would convert the HTML source that we get into a form that LXML works on\n","      table_html = table_body[0].get_attribute('innerHTML')\n","      table_tree = html.fromstring(table_html)\n","\n","      # Using LXML, we would isolate all table row into a list\n","      rows = table_tree.cssselect(\"tr\")\n","\n","      for row in rows:\n","        # From this table row, we would extract all the content of every table cell\n","        # and store it to our list\n","        temp = []\n","        for col in row.cssselect(\"td\"):\n","          temp.append(col.text)\n","\n","        # To make our dataset easier to navigate, we will also add the stock\n","        # name and stock code to our list\n","        temp = [stock[\"name\"], stock_code] + temp\n","        stock_data.append(temp)\n","\n","      # We would now add this newly collected data to our historical_data list\n","      historical_data += stock_data\n","\n","      # To keep track and now that our script is working, we would print a message\n","      # containing a summary of the scraping's progress\n","      print(\"(\", count, \"/ 303 ) Retrieved\", stock_code, \"with\", len(stock_data), \"rows [\", stock_data[0][2], \" - \", stock_data[-1][2], \"]\")\n","    except Exception as e:\n","      # We might also encounter an error where our collection script fails,\n","      # in the rare case where this would happen we would need to manually\n","      # revisit what went wrong and fix it.\n","      print(\"(\", count, \"/ 303 ) Error occured while retrieving\", stock[\"name\"])\n","\n","  return historical_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNhHYXFSUc_q"},"source":["# Declare our column names\n","columns = [\"Stock Name\", \"Code\", \"Date\", \"Price\", \"Open\", \"High\", \"Low\", \"Volume\", \"Change%\"]\n","\n","# Invoke the function that scrapes the data\n","all_data = get_historical_data(stock_links)\n","\n","# Create a dataframe containing our data and declared columns\n","pd_data = pd.DataFrame(all_data, columns=columns)\n","\n","# Finally, let us export it to a CSV file or any file format that you want\n","pd_data.to_csv(\"stocks.csv\", index=False)"],"execution_count":null,"outputs":[]}]}